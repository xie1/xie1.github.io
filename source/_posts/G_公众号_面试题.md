
##G_公众号_面试题

###一、高并发架构
####1、消息队列
#####1.1、什么是消息队列？
	消息队列是，消息中间件，它通过消费者对队列中的消息进行消费。引起消息队列是为了解决应用场景，解耦，异步，削峰。解决分布式事务的最终一致性问题。
	弊端：增加系统架构的复杂性，不易于系统的问题的定位

#####1.2、消息队列有什么优缺点？
	1、优点：在特殊场景下的好处，解耦，异步，削峰
	2、缺点：
		1、系统可用性降低（如何保证消息队列的高可用？系统引入的外部依赖越多，越容易挂掉）
		2、系统复杂度提高（如何保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性）
		3、一致性问题（A系统处理完了直接返回成功，都以为你请求就成功，但是要是BCD三个系统，BD两个系统写入成功，但是C系统写入失败）
				
#####1.3、Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？
	1、单机吐量，activeMQ和rabbitMQ在W级，RocketMQ和kafka在10W级
	2、时效性，除了rabbitMQ在微秒级，其他都是在ms级
	3、可用性，activeMQ和rabbitMQ在主从架构，可用性高，RocketMQ和kafka在是分布式框架，非常高
	4、消息可靠性，activeMQ有较低的丢失数据，其他三个基本不丢
	5、功能支持：activeMQ功能相对比较稳定==


#####1.4、如何保证消息队列的高可用？
	RabbitMQ的高可用性
	RabbitMQ比较有代表性，因为是基于主从（非分布式）做的高可用性，
	RabbitMQ有三种模式：单机模式，普通集群模式，镜像集群模式
	1、单机模式一般属于Demo级别
	2、普通集群模式（无高可用性）提高吞吐量
		在多台机器上启动多个RabbitMQ实例，每个机器启动一个。你创建的queue，只能放会在一个RabbitMQ实例上，每个实例都同步queue的元数据（元数据可用认为是queue的一些配置信息，通过RabbitMQ实例，可用找到queue所在的实例）你消费的时候，实际上如果连接到另外一个实例，那么那个实例会从queue所在实例上拉取数据过来

		缺点：
			1、MQ集群内部会产生大量的数据传输
			2、可用性无保证，queue所在节点宕机，数据就丢失。

	3、镜像集群模式（高可用性）
		在镜像集群模式下，你创建的queue，无论元数据还是queue里的消息都会存在多个实例上，就是说，每个RabbitMQ节点都有这个queue的一个完整镜像，包含queue的全部数据。然后每次你写消息queue的时候，都会自动把消息同步到多个实例queue
		开启方式：在RabbitMQ的管理后台，新增一个镜像集群的策略
		
		缺点：
			1、网络带宽压力和消费很重
			2、不是分布式，就没有扩展性可言
#####1.5、如何保证消息不被重复消费或保证消息的幂等性？
	1、首先清楚MQ怎么出现重复消息的？
		1、例如kafka，在消费者的消费了消息了，一段时间的再提交offset到Zk，消费者这边重启了，MQ并未知道你已经消费了。
		2、在消费者重启好之后，又会接收到之前原来的消息队列。
	2、如何保证消息不被重复消息或幂等性？
		结合自己的业务来控制保证幂等性：
		1、拿数据库要写库，会根据主键查询一下，数据有了，就update
		2、基于数据库唯一键来保证重复数据不会重复插入多条，因为有唯一键约束，重复数据插入只会报错，不会导致数据库中出现脏数据。
		3、在redis存入之前的消费过的消息，在插入数据库之前，先做下判断先。

#####1.6、如何保证消息可靠传输或者处理消息丢失问题？
	1、清楚可能会丢失的地方？
		1、生产者
		2、消息队列
		3、消费者
	2、解决的方案：
		1、生产者：
			1、开启事务同步（吞吐量会下来，因为太耗性能）
			2、开启confirm模式确认机制（异步，优先使用）
		2、MQ
			1、开启持久化
				1、创建消息队列的queue时候将其持久化。可以保证RabbitMQ持久化元数据
				2、发送消息的时候将消息的deliver设置为2
		3、消费者：
			1、关闭RabbitMQ自动ACK

		
			
#####1.7、如何保证消息顺序性？
	1、是否了解顺序这个事？
		1、如果消息是，增加，修改，删除。不能变为删除，增加，修改
		
	2、消息顺序错乱场景及产生原因？
		RabbitMQ：一个消息队列对应多个消费者，消费者消费的顺序和时机不同，导致准备插入数据库的时候出现顺序不一致
		
	3、有没有办法保证消息是有顺序消费？
		rabbitMQ:
		1、如果有很多的消费者的，Rabbit拆分多个queue,每个queue一个consumer，把需要保证的顺序的消息，全部发到一个queue上，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理

		kafka:
		1、通过某个key对消息进行hash取模，分发到到对应的消费者上，在消费者里面创建多个内存队列，分发到对应的内存队列，进行串行化排队，保证消息的顺序，而且即使是在多线程并发下，也可以保证顺序消费。
			
#####1.8、如何保证业务执行和消息发送的一致性？
	  1、发送消息给消息中间件
	  2、消息中间件入库消息（消息状态待处理）
	  3、消息中间件返回结果
	  4、业务操作
	  5、发送业务操作结果给消息中间件
	  6、更改存储中消息状态（消息状态待发送）

#####1.9、如何解决消息队列的延时以及过期失效问题？
	主要是消费端出现问题，没有进行消费
	1、解决方案：
		1、扩容消费端，提供消费
		2、批量重导克服mq中的消息过期失效
		3、消费一个丢弃一个，主要为了克服mq快些满的情况
#####1.10、如果让你写一个消息队列，该如何进行架构设计？说一下你的思路？
	1、mq得支持可伸缩性
	2、mq数据要不要落地磁盘
	3、mq的可用性
	4、mq的数据0丢失等等


####2、缓存
#####2.1、项目中缓存是如何使用的？为什么要用缓存？（高并发，高性能）缓存使用不当会造成什么后果？
	1、分词词库，苗木超市列表，采购单服务列表等
	2、高并发（缓存是走内存的，内存天然就支撑高并发），高性能
	3、后果：
		1、缓存、数据库双写不一致
		2、缓存雪崩、缓存穿透
		3、缓存并发竞争
	

#####2.2、redis 和 memcached 有什么区别？redis的线程模型是什么？为什么redis单线程却能支持高并发？
	1、区别：
		1、数据类型
		2、是否支持持久化
		3、分布式
		4、内存管理机制
	2、redis的单线程模式
		redis内部是文件事件处理器，这个文件事件处理器是单线程，所以redis也是单线程的。文件事件处理器的结构包含 4 个部分：
		多个 socket
		IO 多路复用程序
		文件事件分派器
		事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

	多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理

	
	3、客户端与redis的一次通信过程
		注意产生的事件有,AE_READABLE,AE_WRITABLE
			
	4、单线程模型效率高：
		1、纯内存操作
		2、基于IO多路复用机制
		3、避免多线程上下切换
		4、C语言实现
		
#####2.3、redis的过期策略有哪些？内存淘汰机制有哪些？
	1、过期策略：
		1、定期删除：随机抽取一些key检查和删除
		2、惰性删除
	2、内存淘汰机制
		1、volatile_lru: 对于标记了过期的key，删除那些最近少用的
		2、volatile_ttl: 对于标记了过期的key，删除那些快要过期的key
		3、volatile_romdam:对于标记了过期的key，随机删除key
		4、all_lru : 全部key，删除最近少用的
		5、all_romdam: 全部key ，随机删除
		6、内存满了，插入抛出异常

	3、使用LinkedHashMap实现一个LRU
	
#####2.4、如何保证 Redis 高并发、高可用？Redis 的主从复制原理能介绍一下么？Redis 的哨兵原理能介绍一下么？
		1、redis实现高并发主要依靠主从架构，一主多从（单主用来写入数据，单机几WQPS，多从用来体用每秒10WQPS）
			如果满足高并发，容纳大量数据，就需要redis集群（每秒几十万读写并发）
		2、redis高可用，主从架构部署，再加上个哨兵，任何一个实例宕机，可以进行主备切换。

#####2.5、持久化有几种？
		1、RDB：生成快照，是对redis中的数据执行周期性持久化
		2、AOF：AOF机制对每条写命令追加至AOF文件，当redis重启时，通过回放AOF日志中的写指令来重新构建整个数据集。

		优缺点：
		1、RDB优缺点
			1、会生成多个数据文件，非常适合做冷备
			2、对redis对外提供读写服务，影响小，可以使redis保持高性能
			3、基于RDB数据文件重启和恢复redis进程，更加快速
			4、会丢失部分时间间隔段数据
			5、如果文件特别大，服务暂停时间长
		2、AOF优缺点
			1、可以保护数据不丢失
			2、没有任何磁盘寻址，写入性能非常高
			3、AOF日志文件的命令可以通过非常可读的方式进行记录，这个特性适合做灾难性误删紧急恢复
			4、同一个数据，AOF日志比较大

		如何选择哪种持久化方式：
		  同事开启两种持久化，用AOF保证数据不丢失，用RDB来做不同程度的冷备

		
#####2.6、Redis 集群模式的工作原理能说一下么？在集群模式下，Redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？如何动态增加和删除一个节点？——》待理解
	1、redis cluster集群原理
	2、算法
		1、hash算法
		2、一致性hash算法
		3、redis cluster 的hash slot 算法




#####2.7、如何保证缓存与数据库的双写一致性？
	一、Cache Aside Pattern
	最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。
	1、读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
	2、更新的时候，先更新数据库，然后再删除缓存
	
	二、双写的核心:读请求和写请求串行化，串到一个内存队列里去。
	1、最初级的缓存不一致问题及解决方案
		问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致
		解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中
		
	2、高并发下比较复杂的数据不一致问题分析及解决方案
		1、首先先删缓存
		2、对于大量的并发的读操作的过来，全部通过某个参数的hash取模路由到服务器的内存队列上，全部串行化排队，排队在写操作的后面
		3、等待写数据库操作完之后，再进行读
		
		注意事项：
			1、读请求长时阻塞
			2、读请求并发量过高
			3、多服务实例部署的请求路由
			4、热点商品的路由问题，导致请求的倾斜

#####2.8、了解什么是 redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？
		1、缓存雪崩
			1、缓存机器挂了，请求全部落到数据库，数据库无法承受而挂掉
			解决办法：
			1、事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃
			2、事中：本地缓存+限流，降级，避免mysql被打死
			3、事后：redis持久化，一旦重启，自动从磁盘恢复，加速恢复缓存数据
		2、缓存穿透
			1、被恶意请求缓存中不存在的数据，导致请求全部落到数据库
			解决办法：
				只要没有查到的，就写入一个空值到缓存中，然后设置一个过期时间
		3、缓存击穿
			1、某个key非常热点，访问频繁，当key失效瞬间，大量请求击穿缓存
			解决办法:
			设置热点永不过期，或通过redis和zookeeper实现互斥锁
#####2.9、Redis 的并发竞争问题是什么？如何解决这个问题？了解 Redis 事务的 CAS 方案吗？
		并发竞争问题：
			1、多客户端同时并发写一个key。
		解决方案：
			1、通过基于zookeeper实现分布式锁
			2、通过CAS类乐观方案
				1、你要写缓存数据，都是从mysql里查出来，都将写入mysql中，写入mysql中的时候必须保存一个时间戳
					从mysql查出来的时候，时间戳也查出来。
				2、每次都要写之前，先判断一下当前这个value的时间戳是否比缓存的value要新，如果新的话，可以写。不然用旧的数据覆盖新的数据



####3、分库分表
#####3.1、为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？
	1、因为分库分表一定是为了支撑高并发、数据量大
		MySQL从单机到多机，能承受的并发增加了多倍
		拆分为多个库，数据库服务器磁盘使用率大大降低
		单表数据量减少，SQL 执行效率明显提升
	
	2、 Sharding-jdbc 和 Mycat（代理层proxy方案）
	3、分库分表的方式：
		1、种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如时间范围来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了
		2、或者是按照某个字段 hash 一下均匀分散，这个较为常用
		这两种方案的优缺点是
#####3.2、现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？
	1、停机迁移方案
		1、通过把老库的数据的写入分库分表中间件，由中间件进行写入新库
	2、双写迁移方案
		1、数据同时写入老库和中间件，由中间件写入分库分表
		2、后台写一个脚本，读取老库的数据，写入到中间件
			1、如果存在了数据，则对比记录的时间，查看是否是最新的，则替换。
	
	


#####3.3、如何设计可以动态扩容缩容的分库分表方案？——》待理解
#####3.4、分库分表之后，id 主键如何处理？
	1、独立的数据库自增生成的ID
	2、UUID
	3、时间戳+其他字段的拼接
		
####4、读写分离
#####4.1、如何实现 MySQL 的读写分离？MySQL 主从复制原理是啥？如何解决 MySQL 主从同步的延时问题？
	MySQL 实际上在这一块有两个机制，一个是半同步复制，用来解决主库数据丢失问题；一个是并行复制，用来解决主从同步延时问题。
	1、这个所谓半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
	2、所谓并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行




####5、高并发系统
#####5.1、如何设计一个高并发系统？
	1、系统拆分
	2、缓存
	3、MQ
	4、分库分表
	5、读写分离
	6、ElasticSearch



###二、分布式系统
####1、为什么要进行系统拆分？
#####1.1、为什么要进行系统拆分？如何进行系统拆分？拆分后不用dubbo可以吗？dubbo和thrift有什么区别呢？
	1、不拆分的时候：代码量大，业务耦合严重，不利于开发，测试，及迭代开发
	2、拆分之后：相互之间的耦合，开发效率提升，适合快速迭代开发
	3、如何进行系统拆分：
		我们进行多轮拆分，先根据业务进行粗拆分，后再慢慢细分。

	 dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡、服务实例上下线自动感知、超时重试

####2、分布式服务框架
#####2.1、说一下的 dubbo 的工作原理？注册中心挂了可以继续通信吗？
	1、Dubbo工作原理
        各层说明：
        第一层：service层，接口层，给服务提供者和消费者来实现的
        第二层：config层，配置层，主要是对dubbo进行各种配置的
        第三层：proxy层，服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton
        第四层：registry层，服务注册层，负责服务的注册与发现
        第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
        
		第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控
        第七层：protocol层，远程调用层，封装rpc调用
        第八层：exchange层，信息交换层，封装请求响应模式，同步转异步
        第九层：transport层，网络传输层，抽象mina和netty为统一接口
        第十层：serialize层，数据序列化层，网络传输需要

	2、Dubbo工作流程
		




#####2.2、dubbo 支持哪些序列化协议？说一下 hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？
	1、dubbo://（推荐）    基于hessian
	2、rmi://           基于java二进制流
	3、hessian://       基于hessian
	4、http://          基于json
	5、webservice://    基于SOAP 文本序列化



#####2.3、dubbo 负载均衡策略和高可用策略都有哪些？动态代理策略呢？
	1、集群容错方案 
		1、Failover Cluster | 失败自动切换，自动重试其它服务器（默认） 
		2、Failfast Cluster | 快速失败，立即报错，只发起一次调用 
		3、Failsafe Cluster | 失败安全，出现异常时，直接忽略 
		4、Failback Cluster | 失败自动恢复，记录失败请求，定时重发
		5、Forking Cluster | 并行调用多个服务器，只要一个成功即返回 
		6、Broadcast Cluster | 广播逐个调用所有提供者，任意一个报错则报错



	2、负载均衡策略：
		1、Random LoadBalance | 随机，按权重设置随机概率（默认） 
		2、RoundRobin LoadBalance | 轮询，按公约后的权重设置轮询比率 
		3、LeastActive LoadBalance | 最少活跃调用数，相同活跃数的随机 
		4、ConsistentHash LoadBalance | 一致性 Hash，相同参数的请求总是发到同一提供者



#####2.4、dubbo 的 spi 思想是什么？
	 类似jdbc思想
	spi，简单来说，就是 service provider interface，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 spi 了，需要根据指定的配置或者是默认的配置，去找到对应的实现类加载进来，然后用这个实现类的实例对象



		
#####2.5、如何基于 dubbo 进行服务治理、服务降级、失败重试以及超时重试？
	1、服务治理：
		1、调用链路自动生成
		2、服务访问压力以及时长统计
		3、其他
			1、服务分层
			2、调用链路失效监控和报警
			3、服务鉴权
			
	2、服务降级
		比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应

		实现过程：
			我们调用接口失败的时候，可以通过 mock 统一返回 null。mock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑

	3、失败重试和超时重试
		1、timeout：一般设置为 200ms，我们认为不能超过 200ms 还没返回 
		2、retries：设置 retries，一般是在读请求的时候，比如你要查询个数据，你可以设置个 retries，如果第一次没读到，报错，重试指定的次数，尝试再次读取

#####2.6、分布式服务接口的幂等性如何设计（比如不能重复扣款）？
	这个应该结合业务来保证幂等性
	实际运作过程中，你要结合自己的业务来，比如说利用 redis，用 orderId 作为唯一键。只有成功插入这个支付流水，才可以执行实际的支付扣款

#####2.7、分布式服务接口请求的顺序性如何保证？
		建议是，你们从业务逻辑上设计的这个系统最好是不需要这种顺序性的保证，因为一旦引入顺序性保障，比如使用分布式锁，会导致系统复杂度上升，而且会带来效率低下，热点数据压力过大等问题

	解决思路1：
		首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上，因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个内存队列里去，强制排队，这样来确保他们的顺序性


#####2.8、如何自己设计一个类似 dubbo 的 rpc 框架？

####3、分布式锁
#####3.1、zookeeper 都有哪些使用场景？
	1、分布式协调
		这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上对某个节点的值注册个监听器，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决
	2、分布式锁
	3、服务发现及注册
#####3.2、使用 redis 如何设计分布式锁？使用 zk 来设计分布式锁可以吗？这两种分布式锁的实现方式哪种效率比较高？
	1、redis分布式锁
		1、redis 最普通的分布式锁
			第一个最普通的实现方式，就是在 redis 里使用 setnx 命令创建一个 key，这样就算加锁
		2、RedLock分布式锁
			RedLock算法：
			1、获取当前时间戳，单位是毫秒；
			2、跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般几十毫秒；
			3、尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；
			4、客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
			5、要是锁建立失败了，那么就依次之前建立过的锁删除；
			6、只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。

	2、Zookeeper分布式锁
		1、创建一个锁目录 /lock 
        2、在 /lock 下创建临时的且有序的子节点，第一个客户端对应的子节点为 /lock/lock-0000000000，第二个为 /lock/lock-0000000001，以此类推
        3、客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁，否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁
        4、执行业务代码，完成后，删除对应的子节点
	3、比较
		1、zk性能高，不需要不断尝试获取锁，只需要注册监听器
####4、分布式事务
#####4.1、分布式事务了解吗？你们如何解决分布式事务问题的？TCC 如果出现网络连不通怎么办？XA 的一致性如何保证？
	1、XA方案
	2、TCC方案
		1、Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。
		2、Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。
		3、Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）
		缺点：严重依赖于你自己写代码来回滚和补偿
	3、本地消息表
		缺点：依赖于数据库的消息表来管理事务
	4、可靠消息最终一致性
		
	5、最大努力通知
		有个专门消费 MQ 的最大努力通知服务
####5、分布式会话
#####5.1、集群部署时的分布式 session 如何实现？

	spring session + redis